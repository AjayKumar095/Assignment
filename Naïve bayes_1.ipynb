{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Na√Øve bayes-1</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Q1. What is Bayes' theorem?</h1>\n",
    "<p><b>Answer.</b></p>\n",
    "<p><strong>Bayes' Theorem:</strong></p>\n",
    " <p>Bayes' theorem based on conditional probability, that mean it give the probability of an event when other event is already occure.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Q2. What is the formula for Bayes' theorem?</h1>\n",
    "<p><b>Answer.</b></p>\n",
    "<p><strong>Bayes' Theorem:</strong></p>\n",
    "<blockquote>\n",
    "  <p>P(A|B) = (P(B|A) * P(A)) / P(B)</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Q3. How is Bayes' theorem used in practice?</h1>\n",
    "<p><b>Answer.</b></p>\n",
    "<ul>\n",
    "  <li>Machine Learning: In machine learning, Bayes' theorem is used in Bayesian inference to update model parameters based on observed data.</li>\n",
    "  <li>Medical Diagnosis: Bayes' theorem is used in medical diagnosis to update the probability of a disease given the results of diagnostic tests and the patient's symptoms.</li>\n",
    "  <li>Spam Filtering: In email spam filtering, Bayes' theorem is used in techniques like Naive Bayes classifiers to classify emails as spam or non-spam.</li>\n",
    "  <li>Risk Assessment: Bayes' theorem is used in risk assessment to update the probability of an event occurring based on new information or observations.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Q4. What is the relationship between Bayes' theorem and conditional probability?</h1>\n",
    "<p><b>Answer.</b></p>\n",
    "<p><strong>Relationship between Bayes' Theorem and Conditional Probability:</strong></p>\n",
    "<blockquote>\n",
    "  <p>Bayes' theorem provides a way to calculate conditional probabilities. It relates the probability of an event A given another event B to the probability of event B given event A, using the formula:</p>\n",
    "  <p>P(A|B) = (P(B|A) * P(A)) / P(B)</p>\n",
    "  <p>Here, P(A|B) is the conditional probability of A given B, P(B|A) is the conditional probability of B given A, P(A) is the prior probability of A, and P(B) is the prior probability of B.</p>\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?</h1>\n",
    "<p><b>Answer.</b></p>\n",
    "<p><strong>How do you choose which type of Naive Bayes classifier to use for any given problem?</strong></p>\n",
    "<ol>\n",
    "  <li><strong>Text Classification:</strong> If the problem involves text data, such as email classification or sentiment analysis, the Multinomial Naive Bayes classifier is often a good choice.</li>\n",
    "  <li><strong>Binary Classification with Discrete Features:</strong> For binary classification tasks where the features are discrete (e.g., presence/absence of certain attributes), the Bernoulli Naive Bayes classifier is suitable.</li>\n",
    "  <li><strong>Continuous Features:</strong> If the features are continuous or follow a normal distribution, the Gaussian Naive Bayes classifier is appropriate.</li>\n",
    "  <li><strong>Experimentation:</strong> Sometimes, it's beneficial to try different Naive Bayes classifiers and compare their performance using cross-validation or other evaluation techniques to determine the most effective one for a particular problem.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Q6. Assignment:</h1>\n",
    "<p><b>Answer.</b></p>\n",
    "\n",
    "<p>To classify the new instance with features X1 = 3 and X2 = 4 using Naive Bayes, we need to calculate the conditional probabilities for each class A and B.</p>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Class</th>\n",
    "    <th>X1=1</th>\n",
    "    <th>X1=2</th>\n",
    "    <th>X1=3</th>\n",
    "    <th>X2=1</th>\n",
    "    <th>X2=2</th>\n",
    "    <th>X2=3</th>\n",
    "    <th>X2=4</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>A</td>\n",
    "    <td>3</td>\n",
    "    <td>3</td>\n",
    "    <td>4</td>\n",
    "    <td>4</td>\n",
    "    <td>3</td>\n",
    "    <td>3</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>B</td>\n",
    "    <td>2</td>\n",
    "    <td>2</td>\n",
    "    <td>1</td>\n",
    "    <td>2</td>\n",
    "    <td>2</td>\n",
    "    <td>2</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<p>Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?</p>\n",
    "<p>For Class A:</p>\n",
    "<ul>\n",
    "  <li>P(X1=3|A) = 4/10</li>\n",
    "  <li>P(X2=4|A) = 3/10</li>\n",
    "  <li>P(A) = 1/2 (equal prior probabilities)</li>\n",
    "</ul>\n",
    "<p>For Class B:</p>\n",
    "<ul>\n",
    "  <li>P(X1=3|B) = 1/7</li>\n",
    "  <li>P(X2=4|B) = 3/7</li>\n",
    "  <li>P(B) = 1/2 (equal prior probabilities)</li>\n",
    "</ul>\n",
    "<p>Now, we can calculate the joint probabilities for each class by multiplying the conditional probabilities:</p>\n",
    "<p>For Class A:</p>\n",
    "<ul>\n",
    "  <li>P(X1=3, X2=4|A) = P(X1=3|A) * P(X2=4|A) = (4/10) * (3/10) = 12/100</li>\n",
    "</ul>\n",
    "<p>For Class B:</p>\n",
    "<ul>\n",
    "  <li>P(X1=3, X2=4|B) = P(X1=3|B) * P(X2=4|B) = (1/7) * (3/7) = 3/49</li>\n",
    "</ul>\n",
    "<p>Since P(X1=3, X2=4|A) * P(A) > P(X1=3, X2=4|B) * P(B), the Naive Bayes classifier would predict the new instance to belong to Class A.</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
